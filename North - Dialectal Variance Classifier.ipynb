{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0fF52rP74Z2X"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from huggingface_hub import hf_hub_download\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "CLLaupFtwZA5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "ySXMPqRTwmTX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LoadLatinDependencies(vectorizer_id: str, model_id: str):\n",
        "  \"\"\"\n",
        "    This function loads the serialized latin detection vectorizer and model.\n",
        "  \"\"\"\n",
        "  vect = joblib.load(\n",
        "    hf_hub_download(repo_id=\"MohamedAmineLayachi/North_Latin_Version\", filename=vectorizer_id)\n",
        "  )\n",
        "  model = joblib.load(\n",
        "    hf_hub_download(repo_id=\"MohamedAmineLayachi/North_Latin_Version\", filename=model_id)\n",
        "  )\n",
        "  return vect, model"
      ],
      "metadata": {
        "id": "EMfot9IcAUt2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LoadArabicDependencies(model_id: str, r_labels=False, only_pipeline=False):\n",
        "  \"\"\"\n",
        "    This function loads the arabic detection model from the huggingface hub.\n",
        "  \"\"\"\n",
        "  labels = ['algeria','tunisia','morocco','egypt']\n",
        "  label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "  id2label = {idx: label for idx, label in enumerate(labels)}\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(labels), id2label=id2label, label2id=label2id)\n",
        "  pipe = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
        "\n",
        "  if r_labels is True and only_pipeline is False:\n",
        "    return pipe, tokenizer, model, {'labels': labels, 'label_id': label2id, 'id_label': id2label}\n",
        "  elif r_labels is False and only_pipeline is False:\n",
        "    return pipe, tokenizer, model\n",
        "  elif only_pipeline is True:\n",
        "    return pipe"
      ],
      "metadata": {
        "id": "etCPGAwvBv5w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LatinPrediction(text: str, vectorizer, model):\n",
        "  \"\"\"\n",
        "   This function takes text in latin characters as input and classify it in the appropriate class.\n",
        "  \"\"\"\n",
        "  feature_vector = vectorizer.transform([text])\n",
        "  return model.predict(feature_vector)"
      ],
      "metadata": {
        "id": "CHM_UO_q6Ho3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ArabicPrediction(text: str, pipeline, show_score=False):\n",
        "  \"\"\"\n",
        "   This function takes text in Arabic characters as input and classify it in the appropriate class.\n",
        "  \"\"\"\n",
        "  if show_score:\n",
        "    return pipeline(text)\n",
        "  else:\n",
        "    return pipeline(text)[0]['label']"
      ],
      "metadata": {
        "id": "tlvfW9UHBqGb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DialectClassifier:\n",
        "  \"\"\"\n",
        "    This is the DialectClassfier, a wrapper object for all the models used in this project.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.LatinVect, self.LatinModel = LoadLatinDependencies(\"North_Latin_CountVectorizer.joblib\", \"North_Latin_MNB_Classifier.joblib\")\n",
        "    self.ArabicPipe = LoadArabicDependencies(\"Oelbourki/northafrica-arabizi-dialect-classifier\", only_pipeline=True)\n",
        "\n",
        "  def predictArabic(self, text):\n",
        "    \"\"\"\n",
        "     This function takes text in Arabic characters as input and classify it in the appropriate class.\n",
        "    \"\"\"\n",
        "    prediction = ArabicPrediction(text, self.ArabicPipe)\n",
        "    return prediction\n",
        "\n",
        "  def predictLatin(self, text):\n",
        "    \"\"\"\n",
        "      This function takes text in latin characters as input and classify it in the appropriate class.\n",
        "    \"\"\"\n",
        "    prediction = LatinPrediction(text, self.LatinVect, self.LatinModel)\n",
        "    return prediction[0]"
      ],
      "metadata": {
        "id": "1ma6BLU0F4rQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DC = DialectClassifier()"
      ],
      "metadata": {
        "id": "bWiiPZBgFdJc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(text, alphabet):\n",
        "  \"\"\"\n",
        "    This function interactes with the gradio interface.\n",
        "  \"\"\"\n",
        "  if text is not None:\n",
        "    if alphabet == 'Latin':\n",
        "      return DC.predictLatin(text).title()\n",
        "    elif alphabet == 'Arabic':\n",
        "      return DC.predictArabic(text).title()\n",
        "  elif text.strip() == '':\n",
        "    return 'Nothing to classify.'\n",
        "  else:\n",
        "    return 'Unsupported :('"
      ],
      "metadata": {
        "id": "luejjCsYwubJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Interface(\n",
        "        fn=classify,\n",
        "        inputs=[\"text\", gr.Dropdown(\n",
        "            [\"Latin\", \"Arabic\"], label=\"Alphabet\"\n",
        "        )],\n",
        "        outputs=[\"text\"],\n",
        "    )\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "cqgtARYHq1FK",
        "outputId": "d21027d6-2086-44e6-a993-4438ceed4c1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a007ec9ea543f4d96e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a007ec9ea543f4d96e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHJpHq7yyQn-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}